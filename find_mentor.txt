희망멘토
-> '서비스 개발팀', '데이터 분석팀'에 근무하시는 분 중에서 오픈소스 활동 및 유용한 정보를 많은 사람들과 공유하는 데에 흥미가 있으신 분

이유
-> 멘토님과의 만남이 없더라도 어떻게든 이 강연을 끝까지 무사히 마치기 위해서 최선의 노력을 다 하겠지만
경험이 조금 더 많고 이론적으로도 더 잘 무장하신 멘토님과 함께라면 제가 유스콘23 을 위해서 준비하고 있는 강연의 완성도를 높일 수 있을 것 같다고 생각해서
멘토님을 찾습니다.

멘토님과 함께하며 채워나가고 싶은 부분
(1) Beats 를 사용할때의 실무적인 장점을 잘 알고 계시다면 도움이 될 것 같습니다. 저는
    서버 프로세스에서 Logstash 로 로그를 직접 transport 하는 경우와
    파일에 먼저 기록한 후 FileBeats 와 같은 프레임워크를 통해서 Logstash 에 로그를 전송하는 경우를 비교했을때
    FileBeats 를 활용하는 것이 보다 안정적이라는 것이 이론적으로 훨씬 안정적이고 여러가지 골치아픈 부분을 해결해준다고는 들었지만
    아무래도 로그 시스템과 관련된 경험이 부족하다보니 논리정연하게 왜 Beats 를 사용하는 것이 보다 효율적인지 생각을 정리하기는 힘들다고 느낍니다.
    멘토님과의 대화를 통해서 제 강연에서 로그 데이터 적재와 관련된 영역을 보완하고 싶습니다.
(2) 저에게 주어진 요구조건은 정적인 메타데이터를 넘어서 시간의 흐름에 따라서 쌓이는 다양한 카테고리의 데이터에 대한 통계적 분석 시스템을 구현하는 것이었습니다.
    요구조건를 만족하는 시스템을 구현해나가는 과정에서 다음과 같은 어려움을 마주했고 이를 어떻게 타파해나갔는지 간략하게 강연에서 설명할 예정입니다.
    - 셋업 과정에서 마주친 어려움
    - Google Analytics API 횟수 제한
    - Elasticsearch 쿼리에 대한 생소함
    - 사용자 지정 시간 범위가 커지면서 예상되는 서버쪽 부하 증가
    - 시간단위, 일단위로 데이터를 적재해두는 데이터베이스 스키마 설계
    - 다중 타임존 지원 요구사항
    하지만 여기 있는 목록들이 세상의 모든 어려움을 포괄할 수 있다고 생각하지 않습니다.
    저의 제한된 경험과 사고를 넘어서 멘토님께서 경험하셨던 어려움과 이에 대한 해결책을 추가할 수 있다면
    보다 완성도 있는 강연이 될거라고 기대합니다.
    관련 경험에 대한 멘토님의 지식과 통찰력을 추가하고 싶습니다.


